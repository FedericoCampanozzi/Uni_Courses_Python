{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regressione non Lineare (parte 2)\n",
    "\n",
    "**Programmazione di Applicazioni Data Intensive**  \n",
    "Laurea in Ingegneria e Scienze Informatiche  \n",
    "DISI - Università di Bologna, Cesena\n",
    "\n",
    "Proff. Gianluca Moro, Roberto Pasolini  \n",
    "`nome.cognome@unibo.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "- Importare i package necessari e configurare l'output di matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di studio: predizione consumo elettricità\n",
    "\n",
    "- Carichiamo i dati già visti nei laboratori precedenti: per ogni giorno degli anni dal 2015 al 2017 abbiamo la temperatura media in una città e il picco registrato di consumo di corrente elettrica\n",
    "  - con l'opzione `index_col` specifichiamo che la colonna `date` costituisce l'indice del DataFrame\n",
    "  - con `parse_dates` indichiamo che i suoi valori vanno interpretati come date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if not os.path.exists(\"power.csv\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(\"https://git.io/vpaM1\", \"power.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://git.io/vpaM1\", index_col=\"date\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vogliamo costruire un modello che consenta la predizione del consumo di corrente sulla base della temperatura in un qualsiasi giorno dell'anno\n",
    "- Come nello scorso laboratorio, suddividiamo i dati in\n",
    "  - un _training set_ `*_train` con i dati relativi all'anno 2015\n",
    "  - un _validation set_ `*_val` con i dati relativi agli anni 2016 e 2017\n",
    "- Per ciascuno estraiamo\n",
    "  - una matrice `X_*` $N\\times 1$ con le osservazioni delle variabili indipendenti: in questo caso una sola, la temperatura\n",
    "  - un vettore `y_*` con gli $N$ corrispondenti valori della variabile dipendente: i consumi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = data.index.year < 2016\n",
    "X_train = data.loc[is_train, [\"temp\"]]\n",
    "y_train = data.loc[is_train, \"demand\"]\n",
    "X_val = data.loc[~is_train, [\"temp\"]]\n",
    "y_val = data.loc[~is_train, \"demand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione dei modelli\n",
    "\n",
    "- Abbiamo visto tre diverse metriche per la valutazione dell'accuratezza dei modelli di regressione\n",
    "  - l'_errore quadratico medio_, usato nella discesa del gradiente ma più difficilmente interpretabile\n",
    "  - l'_errore relativo_, che indica intuitivamente la percentuale di errore del modello\n",
    "  - il _coefficiente R²_, che esprime l'accuratezza con un indice tra 0 e 1\n",
    "- Riprendiamo la funzione `print_eval` definita nella scorsa esercitazione per calcolare e stampare le tre metriche su un set di dati e un modello indicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE e R^2 sono incluse in scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# definisco l'errore relativo\n",
    "def relative_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "def print_eval(X, y, model):\n",
    "    preds = model.predict(X)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    re = relative_error(y, preds)\n",
    "    r2 = r2_score(y, preds)\n",
    "    print(f\"   Mean squared error: {mse:.5}\")\n",
    "    print(f\"       Relative error: {re:.5%}\")\n",
    "    print(f\"R-squared coefficient: {r2:.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Riprendiamo anche la funzione `plot_model_on_data` per visualizzare un grafico del modello addestrato sovrapposto ai dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_on_data(X, y, model=None):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(X, y)\n",
    "    if model is not None:\n",
    "        xlim, ylim = plt.xlim(), plt.ylim()\n",
    "        line_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "        line_y = model.predict(line_x[:, None])\n",
    "        plt.plot(line_x, line_y, c=\"red\", lw=3)\n",
    "        plt.xlim(xlim); plt.ylim(ylim)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Temperatura (°C)\"); plt.ylabel(\"Consumi (GW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 1: Ripasso modelli\n",
    "\n",
    "Addestrare sul training set creato sopra tre modelli diversi con le seguenti configurazioni, per ciascuno stampare le misure di valutazione sul validation set e visualizzare il modello sovrapposto ad esso\n",
    "\n",
    "- **(1a)** regressione lineare semplice\n",
    "- **(1b)** regressione polinomiale di grado 2\n",
    "- **(1c)** regressione polinomiale di grado 3 con standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sono eseguiti quì tutti gli import necessari da scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regLin = LinearRegression()\n",
    "regLin.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, regLin)\n",
    "plot_model_on_data(X_val, y_val, regLin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regPoly2 = Pipeline([\n",
    "    (\"poly\",PolynomialFeatures(degree=2,include_bias=False)),\n",
    "    (\"linReg2\",LinearRegression())\n",
    "])\n",
    "regPoly2.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, regPoly2)\n",
    "plot_model_on_data(X_val, y_val, regPoly2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regPoly3 = Pipeline([\n",
    "    (\"poly\",PolynomialFeatures(degree=3,include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"linReg3\",LinearRegression())\n",
    "])\n",
    "regPoly3.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, regPoly3)\n",
    "plot_model_on_data(X_val, y_val, regPoly3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Regolarizzazione e regressione ridge\n",
    "\n",
    "- Abbiamo visto come l'addestramento di un modello si compia minimizzando l'errore sui dati di addestramento, dato da\n",
    "$$ E = \\mathrm{media}\\left(\\left(\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right)^2\\right) $$\n",
    "- Per l'esattezza, la formula su cui si basa `LinearRegression` è\n",
    "$$ E = \\left\\Vert\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right\\Vert_2^2 $$\n",
    "- Dove la _norma euclidea_ (o _norma 2_) $\\left\\Vert\\mathbf{x}\\right\\Vert_2$ di un vettore $\\mathbf{x}$ di $n$ elementi è\n",
    "$$ \\left\\Vert\\mathbf{x}\\right\\Vert_2 = \\sqrt{\\sum_{i=1}^n x_i^2} = \\sqrt{x_1^2+\\ldots+x_n^2} $$\n",
    "- Tuttavia, questo non garantisce l'accuratezza del modello in generale\n",
    "- Soprattutto se il modello ha molti parametri, è possibile che questi vengano \"forzati\" a funzionare bene sui dati d'addestramento, rendendo però il modello poco accurato in generale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- Addestriamo ad esempio un modello polinomiale di grado 30 con standardizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=30, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "prm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Valutiamone le misure di accuratezza sia sul training set che sul validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_train, y_train, prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_val, y_val, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La differenza tra le misure suggerisce che il modello sia stato addestrato \"troppo bene\" sul training set ma non sia abbastanza generale (_overfitting_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- A dimostrazione, si veda il grafico del modello sovrapposto ai dati del training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_on_data(X_train, y_train, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Soprattutto nella parte a sinistra, si nota che il modello è stato ottimizzato per minimizzare l'errore anche in casi estremi del training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Vediamo ora il modello sovrapposto al validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_on_data(X_val, y_val, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si nota che nei casi estremi del validation set, diversi da quelli del training set, l'errore del modello è molto alto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Vediamo quali sono i coefficienti del modello addestrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm.named_steps[\"linreg\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I coefficienti per i termini di grado più alto sono molto alti in valore assoluto (fino a ${10}^{12}$)\n",
    "- Questo causa l'andamento irregolare del modello nei casi estremi e i conseguenti errori\n",
    "- Come evitare che i coefficienti assumano tali valori?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La **_regolarizzazione_** modifica la funzione d'errore su cui si basa l'addestramento, aggiungendo una penalità per valori estremi dei parametri del modello\n",
    "- Nella regolarizzazione _L2_, la più comune, la penalità è proporzionale al quadrato della norma euclidea del vettore $\\mathbf{\\theta}$ dei parametri\n",
    "  - in questo modo parametri molto alti in valore assoluto sono molto penalizzati\n",
    "- La regressione _ridge_ consiste nella regressione lineare con applicata la regolarizzazione L2, utilizzando quindi la seguente funzione d'errore:\n",
    "$$ E = \\left\\Vert\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right\\Vert_2^2 + \\alpha\\left\\Vert\\mathbf{\\theta}\\right\\Vert_2^2 $$\n",
    "- $\\alpha$ è un parametro impostabile dall'utente che controlla il \"peso\" della regolarizzazione\n",
    "  - tali parametri impostabili sono a volte detti _iperparametri_ per distinguerli dai parametri addestrabili del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per eseguire la regressione ridge usiamo un modello `Ridge`\n",
    "- Alla creazione del modello è possibile specificare il peso della regolarizzazione con l'opzione `alpha`\n",
    "- Per il resto l'API della classe `Ridge` è identica a quella di `LinearRegression`, possiamo quindi sostituirla nella pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rrm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=30, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"linreg\", Ridge(alpha=1))  # <-- sostituice LinearRegression()\n",
    "])\n",
    "rrm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Verifichiamo i coefficienti del modello addestrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrm.named_steps[\"linreg\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vediamo che questa volta sono tutti inferiori a 1 in valore assoluto, per effetto della regolarizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Con tali, coefficienti, il modello ha un comportamento regolare anche per casi estremi, come si può vedere dal grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_on_data(X_val, y_val, rrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Verifichiamo l'accuratezza su training e validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_train, y_train, rrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_val, y_val, rrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vediamo che le misure sul training set sono di poco peggiori, ma quelle sul validation set (più importanti) sono nettamente migliori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 2: Regressione polinomiale al variare di grado e regolarizzazione\n",
    "\n",
    "- **(2a)** Definire una funzione `test_regression` con parametri `degree` e `alpha` che\n",
    "  - definisca un modello di regressione polinomiale di grado `degree` con standardizzazione dei dati e regolarizzazione L2 con peso `alpha`\n",
    "  - _(già implementato)_ addestri tale modello sui dati `X_train`, `y_train`\n",
    "  - _(già implementato)_ restituisca il coefficiente R² del modello calcolato sui dati `X_val`, `y_val`\n",
    "- **(2b)** Generare una lista, array o serie di valori restituiti dalla funzione con `alpha=0.01` e `degree` variabile con valori da 3 a 30\n",
    "- **(2c)** Ripetere il punto 2b con `alpha=10`\n",
    "- **(2d)** Visualizzare i risultati in un grafico a linea (`plt.plot`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regression(degree, alpha):\n",
    "    rrm = Pipeline([\n",
    "        (\"poly\",   PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        (\"scale\",  StandardScaler()),\n",
    "        (\"linreg\", Ridge(alpha=alpha))  # <-- sostituice LinearRegression()\n",
    "    ])\n",
    "    rrm.fit(X_train, y_train)\n",
    "    return rrm.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "alpha = 0.01\n",
    "degrees = []\n",
    "coef_R2 = []\n",
    "for deg in range(3,31):\n",
    "    degrees.append(deg)\n",
    "    coef_R2.append(test_regression(deg, alpha))\n",
    "plt.plot(degrees, coef_R2, 'r-o');\n",
    "alpha = 10\n",
    "degrees = []\n",
    "coef_R2 = []\n",
    "for deg in range(3,31):\n",
    "    degrees.append(deg)\n",
    "    coef_R2.append(test_regression(deg, alpha))\n",
    "plt.plot(degrees, coef_R2, 'b-o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soluzione ottima\n",
    "min_deg, max_deg = 3, 30\n",
    "a1, a2 = 0.01, 10\n",
    "degrees = range(min_deg, max_deg + 1)\n",
    "score_1 = [test_regression(degree, a1) for degree in degrees]\n",
    "score_2 = [test_regression(degree, a2) for degree in degrees]\n",
    "plt.plot(degrees, score_1, 'r-o');\n",
    "plt.plot(degrees, score_2, 'b-o');\n",
    "plt.legend([f\"alpha={a1}\",f\"alpha={a2}\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di studio: Predizione dei prezzi delle case\n",
    "\n",
    "- Riprendiamo dalla scorsa esercitazione il dataset relativo ai prezzi delle case\n",
    "- Forniamo tale dataset all'URL https://git.io/fjGjx già adattato per essere caricato con `read_csv` con le opzioni di default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if not os.path.exists(\"housing.csv\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(\"https://git.io/fjGjx\", \"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lista delle variabili\n",
    "\n",
    "- CRIM: tasso di criminalità pro capite per zona\n",
    "- ZN: proporzione terreno residenziale per lotti maggiori di 25.000 piedi quadrati (circa 2300 m2)\n",
    "- INDUS: proporzione di acri industriali non commerciali per città\n",
    "- CHAS: variabile fittizia Charles River, 1 se il tratto affianca il fiume, altrimenti 0\n",
    "- NOX: concentrazione di ossido d’azoto (parti per 10 milioni)\n",
    "- RM: numero medio di stanze per abitazione\n",
    "- AGE: proporzione delle unità abitate costruite prima del 1940\n",
    "- DIS: distanze pesate verso i cinque uffici di collocamento di Boston\n",
    "- RAD: indice di accessibilità rispetto alle grandi vie radiali di comunicazione\n",
    "- TAX: tasso di imposte sulla casa per 10.000 dollari\n",
    "- PTRATIO: rapporto allievi-docenti per città\n",
    "- B: 1000(Bk - 0.63)2, dove Bk è la proporzione di persone di origine afroamericana\n",
    "- LSTAT: percentuale di popolazione con basso reddito\n",
    "- **MEDV: valore mediano delle abitazioni di proprietà in migliaia di dollari**\n",
    "  - vogliamo stimare il valore di questa variabile in funzione delle altre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estraiamo dal frame\n",
    "  - la serie `y` con i valori della variabile `MEDV` da prevedere\n",
    "  - il frame `X` con i valori di tutte le altre variabili, utilizzabili per la predizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = housing[\"MEDV\"]\n",
    "X = housing.drop(columns=\"MEDV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Dividiamo i dati caricati casualmente in training e validation set con la funzione `train_test_split`\n",
    "  - con `test_size` indichiamo quanti dati vanno nel validation set, i restanti andranno nel training set\n",
    "  - con `random_state` fissiamo un seed per la suddivisione casuale\n",
    "  - la funzione mescola i dati di `X` e `y` in modo congiunto, mantenendo la corrispondenza esistente tra le posizioni dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi coefficienti modelli\n",
    "\n",
    "- Addestriamo e verifichiamo l'accuratezza di tre diversi modelli sui dati:\n",
    "  - **(a)** regressione lineare semplice\n",
    "  - **(b)** regressione lineare con regolarizzazione L2 (regressione ridge), assumendo $\\alpha=1$\n",
    "  - **(c)** regressione lineare con standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = LinearRegression()\n",
    "model_a.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = Ridge(alpha=10)\n",
    "model_b.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "model_c.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo ora in un unico frame i coefficienti di tutti e tre i modelli (una riga per variabile, una colonna per modello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"linear\": model_a.coef_,\n",
    "    \"ridge\": model_b.coef_,\n",
    "    \"scaled\": model_c.named_steps[\"lr\"].coef_\n",
    "}, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In tutti e tre i modelli, dai segni dei coefficienti possiamo vedere quali fenomeni influiscono positivamente e negativamente sul prezzo\n",
    "  - ad es. il prezzo delle case è più alto se vicine al fiume (`CHAS`), mentre decresce con la criminalità (`CRIM`)\n",
    "- Nella regressione ridge i valori assoluti più alti sono ridotti (es. `NOX` e `RM`)\n",
    "- Con la standardizzazione delle feature otteniamo valori su scale simili, che possiamo confrontare alla pari\n",
    "  - ad es. negli altri modelli il coefficiente di `NOX` è alto in valore assoluto perché i valori di tale variabile sono bassi (la media è circa 0.55, contro quelle superiori a 3 delle altre variabili)\n",
    "  - nel modello con standardizzazione assumono invece più peso il numero di stanze (`RM`) e la distanza dagli uffici di collocamento (`DIS`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione Lasso\n",
    "\n",
    "- La regolarizzazione L2 impedisce che i parametri del modello assumano valori troppo alti\n",
    "- I valori dei parametri sono comunque tutti non nulli, tutte le variabili vengono coinvolte nella predizione\n",
    "- Vorremmo addestrare un modello meno complesso, dove alcuni parametri hanno valori nulli, **ignorando completamente le variabili meno rilevanti**\n",
    "  - ad es. variabili con valori dipendenti da altre (_multicollinearità_)\n",
    "- Questo si può ottenere tramite la regolarizzazione L1, basata sulla norma 1, definita su un vettore $\\mathbf{x}$ di $n$ elementi come\n",
    "$$ \\left\\Vert\\mathbf{x}\\right\\Vert_1 = \\sum_{i=1}^n{\\left\\vert x_i\\right\\vert} = \\left\\vert x_1\\right\\vert+\\ldots+\\left\\vert x_n\\right\\vert $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La regressione _lasso_ consiste nella regressione lineare con regolarizzazione L1, basata quindi sul minimizzare la funzione d'errore\n",
    "$$ E = \\frac{1}{2m}\\left\\Vert\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right\\Vert_2^2 + \\alpha\\left\\Vert\\mathbf{\\theta}\\right\\Vert_1 $$\n",
    "- Come per la regressione ridge, il parametro $\\alpha$ controlla il peso della regolarizzazione\n",
    "- La regressione lasso si esegue usando un modello `Lasso`, su cui possiamo impostare come in `Ridge` il parametro `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", Lasso(alpha=1))\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Vediamo i coefficienti del modello risultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.named_steps[\"regr\"].coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La regolarizzazione L1 ha contribuito ad annullare quanti più coefficienti possibile, creando un modello che considera solo 3 variabili\n",
    "- Ma qual'è l'accuratezza di tale modello?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'accuratezza è peggiore rispetto ai casi precedenti: in questo caso la regolarizzazione è stata eccessiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede diminuendo il parametro `alpha`, ovvero il peso della regolarizzazione?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", Lasso(alpha=0.2)) # <-- cambiato da 1\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(model.named_steps[\"regr\"].coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I coefficienti non nulli sono aumentati da 5 a 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'accuratezza è di poco inferiore a quella ottenuta con gli altri modelli\n",
    "- Questo modello richiede però solo 9 variabili invece di 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Elastic Net\n",
    "\n",
    "- La regressione _elastic net_ combina insieme le regolarizzazioni L2 e L1 usate in ridge e lasso\n",
    "- Si applica in scikit-learn tramite la classe `ElasticNet`, per cui l'errore è calcolato come:\n",
    "$$ E = \\underbrace{\\frac{1}{2m} ||X\\theta - y||_2 ^ 2}_{\\text{errore sui dati}} + \\underbrace{\\alpha \\rho ||\\theta||_1}_{\\text{L1}} + \\underbrace{\\frac{\\alpha(1-\\rho)}{2} ||\\theta||_2 ^ 2}_{\\text{L2}} $$\n",
    "- I parametri impostabili sono\n",
    "  - `alpha` ($\\alpha$) che determina il peso generale della regolarizzazione\n",
    "  - `l1_ratio` ($\\rho$, compreso tra 0 e 1) che determina il peso di L1 relativo al totale (con $\\rho=1$ si ha la regressione lasso, con $\\rho=0$ la ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = Pipeline([\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"regr\", ElasticNet(alpha=0.2, l1_ratio=0.1))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "print(len(X_val), len(y_val))\n",
    "print_eval(X_val, y_val, model)\n",
    "# plot_model_on_data(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 3: Elastic Net con pesi separati\n",
    "\n",
    "- **(3a)** Definire una funzione `elastic_net_with_alphas` che restituisca un modello elastic net (non addestrato) con pesi dati separatamente per la regolarizzazione L2 e L1\n",
    "  - si ricordi che il parametro `alpha` è la somma dei due pesi\n",
    "- **(3b)** Servendosi di tale funzione, addestrare e validare un modello elastic net con $\\alpha_{L2}=1, \\alpha_{L1}=0.1$ e standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_with_alphas(alpha_l2, alpha_l1):\n",
    "    alpha = alpha_l1 + alpha_l2\n",
    "    l1_ratio = alpha_l1 / alpha\n",
    "    return ElasticNet(alpha=alpha, l1_ratio=l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_en = elastic_net_with_alphas(1,0.1)\n",
    "pl = Pipeline([\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"ElasticNet\", model_en)\n",
    "])\n",
    "pl.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, pl)\n",
    "print(len(X_val), len(y_val))\n",
    "# plot_model_on_data(X_val, y_val, pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressione polinomiale multivariata\n",
    "\n",
    "- Abbiamo visto in precedenza la regressione polinomiale su una sola variabile $X$ (univariata), corrispondente alla regressione lineare sulle variabili $X,X^2,X^3,\\ldots$\n",
    "- Per generare queste variabili utilizziamo il filtro `PolynomialFeatures`\n",
    "- Siano date ad esempio due osservazioni di una variabile..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([ [ 2],\n",
    "                    [-3] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo ottenere ad es. le potenze fino al 4° grado\n",
    "  - `include_bias=True` specifica di non includere il termine di grado 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(sample)\n",
    "#         X   X^2   X^3   X^4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In presenza di più di una variabile, la regressione polinomiale genera tutti i possibili termini fino al grado impostato, includendo anche **termini basati su più variabili**\n",
    "- Vediamo un esempio con 2 generiche variabili $A$ e $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                     A   B\n",
    "sample = np.array([ [ 2, -3],\n",
    "                    [ 4, -5] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applicando il filtro `PolynomialFeatures` con grado 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(sample)\n",
    "#         A     B    A^2   A*B   B^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le variabili generate (escludendo il grado nullo) sono 5: $A,B,A^2,AB,B^2$\n",
    "- Oltre ai quadrati delle singole variabili abbiamo quindi anche i prodotti tra di esse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo usare il metodo `get_feature_names_out` del filtro per avere un array delle variabili calcolate (`get_feature_names` in versioni più vecchie di scikit-learn)\n",
    "  - il filtro deve già essere stato \"addestrato\" con `fit` o `fit_transform`\n",
    "  - è possibile passare una lista di nomi delle variabili originali, altrimenti sono usati `x0`, `x1`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando il grado massimo, le variabili generate **aumentano rapidamente**\n",
    "- Ad esempio, aumentando il grado da 2 a 3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ...generiamo 9 variabili, ovvero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede con un numero iniziale di variabili più alto?\n",
    "- Selezioniamo ad esempio dalle variabili X del dataset le 5 feature che avevano coefficiente non nullo nella prima regressione Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la lista delle feature da considerare è:\n",
    "Xsub_feats = [\"CHAS\", \"RM\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "# creo una selezione sia dal training che dal validation set\n",
    "Xsub_train = X_train[Xsub_feats]\n",
    "Xsub_val = X_val[Xsub_feats]\n",
    "# stampo il numero di colonne\n",
    "Xsub_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generando le feature polinomiali con grado massimo 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ...otteniamo 20 feature distinte!\n",
    "- Le feature includono infatti tutte le possibili coppie di variabili, oltre ai quadrati di ciascuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out(Xsub_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando ulteriormente il grado, il numero di variabili cresce esponenzialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possiamo usare un ciclo for per testare rapidamente valori successivi\n",
    "for degree in range(3, 9):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    feats_count = poly.fit_transform(Xsub_train).shape[1]\n",
    "    print(f\"{degree}° grado: {feats_count} variabili\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Questa crescita è ancora più evidente con la matrice completa `X_train`, con 13 variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generando le feature polinomiali con grado massimo 2 otteniamo 104 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando ulteriormente il grado, il numero di variabili cresce enormemente\n",
    "  - con grado 10 si supera il milione di variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in range(3, 8):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    feats_count = poly.fit_transform(X_train).shape[1]\n",
    "    print(f\"{degree}° grado: {feats_count} variabili\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- All'aumentare delle variabili, aumenta il tempo necessario per l'addestramento del modello\n",
    "- Prendiamo ad esempio come riferimento un modello ElasticNet polinomiale con standardizzazione delle feature generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_std_elasticnet(degree):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        (\"std\",  StandardScaler()),\n",
    "        (\"regr\", ElasticNet(alpha=0.5, l1_ratio=0.2))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Eseguiamo la prova su un modello di grado 2 sia col sottoinsieme di 5 feature indicato sopra che con tutte le feature\n",
    "- Usiamo il comando \"magico\" `%time` per riportare in output il tempo di esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = poly_std_elasticnet(2)\n",
    "%time model.fit(Xsub_train, y_train)\n",
    "print_eval(Xsub_val, y_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = poly_std_elasticnet(2)\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'addestramento richiede una frazione di secondo, anche per via del numero limitato di istanze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Verifichiamo ora cosa accade in entrambi i casi con grado 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = poly_std_elasticnet(5)\n",
    "%time model.fit(Xsub_train, y_train)\n",
    "print_eval(Xsub_val, y_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = poly_std_elasticnet(5)\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'accuratezza del modello migliora sensibilmente, ma **con tempi di addestramento molto superiori**\n",
    "  - più di 10 volte superiori con 5 feature\n",
    "  - più di 100 volte superiori con 13 feature\n",
    "  - con dataset più grandi, avremmo tempi di addestramento insostenibili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione con funzioni kernel\n",
    "\n",
    "- Nella regressione polinomiale si eseguono prodotti tra dati con dimensioni aggiunte e rappresentate esplicitamente\n",
    "- Le _funzioni kernel_ permettono di calcolare gli stessi prodotti senza calcolare esplicitamente le dimensioni aggiunte\n",
    "- Questo permette di ottenere **modelli non lineari senza l'aggiunta di variabili**\n",
    "- Esistono diverse funzioni kernel utilizzabili con diversi parametri impostabili\n",
    "- Ad esempio, il kernel polinomiale è definito dalla formula\n",
    "$$ K(\\mathbf{a},\\mathbf{b}) = \\left(\\mathbf{a}\\cdot\\mathbf{b}+c\\right)^d $$\n",
    "  - $d$ e $c$ sono parametri del kernel, in particolare $d$ è il grado del polinomio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La classe `KernelRidge` implementa la regressione ridge con l'applicazione di una funzione kernel\n",
    "- Col parametro `kernel` si indica il tipo di kernel con una stringa, ad es. `\"poly\"` per un kernel polinomiale\n",
    "- Ulteriori parametri riguardano il kernel, per quello polinomiale sono `degree` ($d$) e `coef0` ($c$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Abbiamo ottenuto un'accuratezza più elevata rispetto ai modelli lineari, ma in tempi molto più brevi rispetto alla regressione polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando arbitrariamente il grado del polinomio, il tempo impiegato per l'addestramento non cambia\n",
    "  - in questo caso comunque un grado alto non porta ad un modello accurato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=15))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Va però ricordato che la complessità cresce quadraticamente col numero di istanze di training\n",
    "- Ad esempio, addestrando un modello su _tutti_ i dati invece che sul solo training set, quindi sul 50\\% di istanze in più..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])\n",
    "%time model.fit(X, y)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ... il tempo necessario è circa il doppio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo testare anche funzioni kernel diverse, ad esempio RBF (_radial basis function_)\n",
    "  - RBF ha valori tanto più elevati quanto più i valori X sono vicini a 0 (ovvero la media, usando dati standardizzati)\n",
    "- La funzione RBF ha la forma di una gaussiana, di cui si può impostare l'ampiezza col parametro `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"rbf\", gamma=0.01))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In questo caso specifico il kernel RBF non funziona bene tanto quanto il polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k-Fold Cross Validation\n",
    "\n",
    "- La _cross validation_ si riferisce in generale alla valutazione di un modello di predizione su dati differenti rispetto a quelli su cui è addestrato\n",
    "- Finora l'abbiamo svolta usando il semplice metodo _hold-out_\n",
    "  - i dati sono suddivisi casualmente in _training set_ e _validation set_ con proporzioni configurabili\n",
    "  - un modello è addestrato sul training set e validato sul validation set\n",
    "- Il metodo _k-fold_ è un'alternativa al metodo hold-out per valutare l'accuratezza di un modello\n",
    "  - i dati sono divisi causalmente in k gruppi (_fold_)\n",
    "  - ciascun gruppo è validato su un modello addestrato su tutti gli altri gruppi\n",
    "  - i risultati dei singoli test sono aggregati\n",
    "- scikit-learn fornisce un supporto generico per la cross-validation di modelli tramite diversi metodi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per prima cosa va creato un oggetto che definisce il metodo di cross-validation da applicare\n",
    "- Usiamo ad esempio un oggetto della classe `KFold`\n",
    "  - il primo parametro è il numero di fold (k) da usare\n",
    "  - specifichiamo inoltre che i dati sono distribuiti casualmente e il seed da usare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gli oggetti di questo tipo forniscono un metodo `split`, che dato un dataset genera le suddivisioni training/validation secondo la configurazione data\n",
    "  - per ogni suddivisione sono dati un array di etichette delle righe da includere nel training set (`train_index`) e l'array complementare di etichette delle righe da includere nel validation set (`val_index`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, val_index) in enumerate(kf.split(X, y), start=1):\n",
    "    print(f\"Fold {i}: {len(train_index)} istanze di training, {len(val_index)} istanze di validazione\")\n",
    "    # per ottenere ad es. X_train: X[train_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definiamo un modello da validare, ad es. il modello kernel ridge visto sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per eseguire la CV usiamo quindi la funzione `cross_validate`, a cui passiamo in input:\n",
    "  - la definizione di un modello, di cui viene addestrata una copia con la stessa configurazione per ciascun fold\n",
    "  - i dati, divisi come per `fit` in valori di variabili indipendenti (X) e dipendente (y)\n",
    "  - l'oggetto che definisce il metodo di CV, in questo caso l'istanza di `KFold`\n",
    "  - l'opzione `return_train_score=True` per ottenere la valutazione di ogni modello anche sui dati di addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_result = cross_validate(model, X, y, cv=kf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Otteniamo un dizionario con un vettore per ciascuna misura estratta, ciascuno ha un valore per ogni fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per operare facilmente, raccogliamo i dati in un frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_table = pd.DataFrame(cv_result)\n",
    "cv_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per ognuno dei 5 fold vediamo riportati\n",
    "  - i secondi impiegati per l'addestramento (`fit_time`) e la validazione (`score_time`) del modello\n",
    "  - lo score calcolato su training set (`train_score`) e validation set (`test_score`)\n",
    "- Lo score è quello calcolato dal metodo `score` del modello, ovvero il coefficiente R²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per avere un dato generale sulla bontà del modello, possiamo calcolare media e deviazione standard degli score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_table[[\"train_score\", \"test_score\"]].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tale valutazione è più affidabile di quella col metodo hold-out, ottenuta da un singolo modello\n",
    "- Ci permette inoltre di valutare la \"robustezza\" del modello, ovvero quanto l'accuratezza sia stabile addestrandosi su set di dati diversi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 4: Cross-validation su modello kernel ridge\n",
    "\n",
    "- **(4a)** Definire un modello di regressione kernel ridge su feature standardizzate con kernel polinomiale di 3° grado e $\\alpha=10$\n",
    "- **(4b)** Eseguire la cross-validation del modello, utilizzando 5 fold dell'intero set di dati (`X` e `y`) generati dall'oggetto `kf` definito sopra\n",
    "- **(4c)** Calcolare la media e la deviazione standard dei punteggi R² ottenuti dalla validazione di ciascun fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"kernel\", KernelRidge(alpha=10, kernel=\"poly\", degree=3))\n",
    "])\n",
    "res = cross_validate(model,X,y,cv=kf)\n",
    "data_res = pd.DataFrame(res)\n",
    "print(f\"deviazione standard : \", data_res[\"test_score\"].std())\n",
    "print(f\"media : \", data_res[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ricerca degli iperparametri con grid search\n",
    "\n",
    "- Sui modelli utilizzati finora abbiamo impostato manualmente i valori di diversi iperparametri\n",
    "  - grado della regressione polinomiale, peso della regolarizzazione, ...\n",
    "- L'accuratezza del modello può dipendere fortemente da questi valori\n",
    "- Scelto un generico modello da utilizzare (es. regressione polinomiale o kernel ridge), vorremmo **individuare i valori degli iperparametri che ne massimizzino l'accuratezza**\n",
    "- scikit-learn fornisce un supporto per eseguire automaticamente la cross validation di un modello con diversi valori degli iperparametri tramite la _grid search_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Consideriamo ad esempio un modello _elastic net_ di cui fissiamo arbitrariamente il parametro `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(l1_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vorremmo trovare il migliore valore possibile del parametro `alpha` tra un insieme di valori possibili, ovvero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_alphas = [0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creiamo una _griglia_ dei parametri, ovvero un dizionario in cui associamo ai nomi dei parametri variabili i valori che possono assumere\n",
    "- In questo caso abbiamo un unico parametro variabile, `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"alpha\": candidate_alphas}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Definiamo ora un modello `GridSearchCV` indicando\n",
    "  - il modello \"base\" con i parametri fissati a priori\n",
    "  - la griglia dei parametri variabili\n",
    "  - un metodo `cv` di cross validation da usare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(model, grid, cv=kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Come per i modelli base, usiamo il metodo `fit` per eseguire l'addestramento, passando la matrice X e il vettore y\n",
    "- Per ogni valore possibile di `alpha`, scikit-learn esegue la cross-validation per calcolare il punteggio R² medio del modello con quel valore di `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In seguito ai test, il modello impostato viene (di default) riaddestrato su tutti i dati forniti, usando gli iperparametri che han dato il miglior punteggio medio\n",
    "- Il modello finale è accessibile all'attributo `gs_best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dall'attributo `best_params_` possiamo vedere quali sono i valori selezionati dalla griglia degli iperparametri per tale modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- L'oggetto `GridSearchCV` addestrato può essere usato come un normale modello di predizione, le chiamate a `predict` e altri metodi sono girate al `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prezzo predetto per la prima riga del validation set\n",
    "gs.predict(X_val.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalente a\n",
    "gs.best_estimator_.predict(X_val.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo valutare il modello sul validation set \"esterno\", non utilizzato nella grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_val, y_val, gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- L'attributo `cv_results_` fornisce risultati dettagliati su tutti gli iperparametri testati\n",
    "- Come per `cross_validate`, raccogliamo i risultati in un `DataFrame` per visualizzarli meglio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dati riportati per ciascun test includono:\n",
    "- `{mean|std}_{fit|score}_time`: media/dev. standard dei tempi di addestramento/valutazione sui diversi fold\n",
    "- `param_X`: valore del parametro X\n",
    "- `params`: dizionario col valore di tutti i parametri\n",
    "- `splitN_test_score`: punteggio della valutazione sull'N-esimo fold\n",
    "- `{mean|std}_test_score`: media/dev. standard dei punteggi sui diversi fold\n",
    "- `rank_test_score`: ranking del punteggio, 1 è il migliore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede con due iperparametri variabili?\n",
    "- Oltre a 3 valori possibili per `alpha`, impostiamo 3 valori possibili anche per `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet()\n",
    "grid = {\n",
    "    \"alpha\":    [0.1, 1, 10],\n",
    "    \"l1_ratio\": [0.1, 0.2, 0.3]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizzo i risultati ordinati per punteggio R² medio decrescente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn ha generato e testato **tutte le combinazioni possibili** dei valori degli iperparametri, in tutto 3×3 = 9 configurazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid search su pipeline\n",
    "\n",
    "- Possiamo usare `GridSearchCV` anche con una pipeline, testando diversi valori anche per i parametri dei filtri\n",
    "- Consideriamo ad esempio un modello polinomiale con regolarizzazione L2, su cui sono variabili\n",
    "  - il grado del polinomio (attributo `degree` del filtro `poly`)\n",
    "  - il peso della regolarizzazione (attributo `alpha` del modello `regr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"poly\",  PolynomialFeatures(include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per riferirsi ai parametri dei singoli componenti, usiamo la notazione `componente__parametro` _(con DUE underscore in mezzo)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"poly__degree\": [2, 3],      # <- grado polinomio\n",
    "    \"regr__alpha\":  [0.1, 1, 10] # <- regolarizzazione\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il resto del procedimento rimane invariato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(model, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Nella pipeline possiamo impostare un intero componente come parametro variabile, con la possibilità di rimuoverlo impostandolo a `None`\n",
    "- Possiamo ad esempio testare un modello con e senza standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", None),   # uso None come segnaposto\n",
    "    (\"regr\",  Ridge())\n",
    "])\n",
    "grid = {\n",
    "    # scale = standardizzazione oppure nulla\n",
    "    \"scale\": [None, StandardScaler()],\n",
    "    \"regr__alpha\": [0.1, 1, 10]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 5: Grid search su regressione kernel ridge\n",
    "\n",
    "- **(5a)** Creare una funzione `grid_test` che, presi in input un modello e una griglia di parametri\n",
    "  - esegua una grid search con `X_train`, `y_train` come dati di addestramento con modello e parametri forniti, usando cross-validation a 5 fold\n",
    "  - stampi (`print(...)`) il dizionario con gli iperparametri selezionati del modello migliore\n",
    "  - stampi le misure di accuratezza (`print_eval`) sui dati `X_val`, `y_val`\n",
    "- **(5b)** Testare con la funzione sopra un modello di regressione elastic net polinomiale con\n",
    "  - grado 2 o 3\n",
    "  - standardizzazione delle feature generate\n",
    "  - `alpha` pari a 0.1, 1 o 10\n",
    "  - `l1_ratio` pari a 0.1, 0.25 o 0.5\n",
    "- **(5c)** Testare con la funzione sopra un modello kernel ridge con\n",
    "  - standardizzazione dei dati\n",
    "  - kernel polinomiale di grado compreso tra 2 e 10\n",
    "  - `alpha` (regolarizzazione) pari a 0.01, 0.1, 1 o 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_test(model, grid):\n",
    "    kf = KFold(5, shuffle=True,random_state=42)\n",
    "    gs = GridSearchCV(model, grid, cv=kf)\n",
    "    gs.fit(X_train, y_train);\n",
    "    print(gs.best_params_)\n",
    "    print_eval(X_val, y_val, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.9802068696158, tolerance: 2.465989197026022\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.1478398344716, tolerance: 2.2563256431226764\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.805283990909174, tolerance: 2.406635866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.99899354066247, tolerance: 2.289231866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 221.26089235944664, tolerance: 2.4742154074074074\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.21537987866577, tolerance: 2.465989197026022\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.869969625351132, tolerance: 2.2563256431226764\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.064804967555574, tolerance: 2.406635866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.090362890022334, tolerance: 2.289231866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.173623307196067, tolerance: 2.4742154074074074\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.122057629660503, tolerance: 2.465989197026022\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.297728688791267, tolerance: 2.4742154074074074\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1088.2700037815016, tolerance: 2.465989197026022\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 860.3798557061807, tolerance: 2.2563256431226764\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 974.5176713289954, tolerance: 2.406635866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 890.4989346967416, tolerance: 2.289231866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1051.199521741033, tolerance: 2.4742154074074074\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 507.09856372433023, tolerance: 2.465989197026022\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 385.2009285608283, tolerance: 2.2563256431226764\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 521.6440445694008, tolerance: 2.406635866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 364.84990944885976, tolerance: 2.289231866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 485.3323852867402, tolerance: 2.4742154074074074\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 327.8201912426655, tolerance: 2.465989197026022\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.07032896323426, tolerance: 2.2563256431226764\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109.88251539776184, tolerance: 2.406635866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 257.05132160675976, tolerance: 2.289231866666667\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 284.9476790830804, tolerance: 2.4742154074074074\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'poly__degree': 2, 'regr__alpha': 0.1, 'regr__l1_ratio': 0.1}\n",
      "   Mean squared error: 15.041\n",
      "       Relative error: 13.87150%\n",
      "R-squared coefficient: 0.80004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 278.6543434186033, tolerance: 2.97696387537092\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", ElasticNet())\n",
    "])\n",
    "grid = {\n",
    "    \"poly__degree\": [2, 3],\n",
    "    \"regr__alpha\": [0.1, 1, 10],\n",
    "    \"regr__l1_ratio\": [0.1, 0.25, 0.5]\n",
    "}\n",
    "grid_test(model, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel__alpha': 1.0, 'kernel__degree': 2}\n",
      "   Mean squared error: 11.303\n",
      "       Relative error: 12.20756%\n",
      "R-squared coefficient: 0.84973\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"kernel\", KernelRidge(kernel=\"poly\"))\n",
    "])\n",
    "\n",
    "grid = {\n",
    "    \"kernel__degree\" : range(2,11),\n",
    "    \"kernel__alpha\" : np.logspace(-2,1,4)\n",
    "}\n",
    "\n",
    "grid_test(model, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested cross-validation\n",
    "\n",
    "- Sopra abbiamo validato il risultato finale della grid search su un validation set separato\n",
    "- La _nested cross-validation_ prevede che siano generati **k fold \"esterni\"** su tutti i dati disponibili e che **per ciascuno** si esegua il tuning degli iperparametri con una cross validation \"interna\" usando le parti di training dei fold esterni\n",
    "- I criteri con cui si eseguono le cross validation esterna ed interna possono differire, es. diverso numero di fold\n",
    "- Ipotizziamo ad esempio di usare 3 fold esterni e 5 interni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(3, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 6: Nested cross validation\n",
    "\n",
    "Completare l'implementazione una funzione `nested_cv` che esegua la nested cross validation di un modello `model` con griglia di parametri variabili `grid`\n",
    "- _(già implementato)_ predisporre una lista vuota in cui salvare i punteggi ottenuti su ogni fold esterno\n",
    "- _(già implementato)_ usare un ciclo `for` per iterare tutti i fold esterni (T, V) del dataset `X`, `y`\n",
    "  - il metodo `split` di `outer_cv` fornisce per ogni fold gli indici delle istanze di training e di validation\n",
    "- su ciascun fold esterno, eseguire la grid search con modello e parametri dati in ingresso alla funzione sui dati T, applicando `inner_cv` come cross validation\n",
    "- per ogni modello generato, salvare nella lista di punteggi il R² ottenuto dalla validazione sui dati V\n",
    "- _(già implementato)_ restituire la lista alla fine del ciclo\n",
    "\n",
    "Testare la funzione su uno dei modelli usati sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(model, grid):\n",
    "    results = []\n",
    "    for train_indices, val_indices in outer_cv.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "        X_val, y_val = X.iloc[val_indices], y.iloc[val_indices]\n",
    "        gs = GridSearchCV(model, grid, cv=kf)\n",
    "        gs.fit(X_train, y_train);\n",
    "        results.append(gs.score(X_val, y_val))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.857809313401843, 0.8443841766460665, 0.8875611674403588]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_cv(model, grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
